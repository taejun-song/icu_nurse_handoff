{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation Inspection\n",
    "\n",
    "Display interpreter input alongside output, highlight duplicates removed and conflicts resolved with reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown, display\n",
    "from src.config import BASELINE_FILE, EXTRACTIONS_DIR, OUTPUT_DIR\n",
    "from src.loader import load_emr_file\n",
    "from src.schemas import ExtractorOutput, InterpreterOutput\n",
    "from src.interpreter import interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Extraction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_outputs: list[ExtractorOutput] = []\n",
    "for p in sorted(EXTRACTIONS_DIR.glob(\"*.json\")):\n",
    "    data = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    extractor_outputs.append(ExtractorOutput.model_validate(data))\n",
    "\n",
    "baseline_sheets = load_emr_file(BASELINE_FILE)\n",
    "print(f\"Loaded {len(extractor_outputs)} extraction files\")\n",
    "print(f\"Loaded {len(baseline_sheets)} baseline sheets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_findings = 0\n",
    "for eo in extractor_outputs:\n",
    "    count = len(eo.findings)\n",
    "    total_findings += count\n",
    "    print(f\"  {eo.sheet_name}: {count} findings\")\n",
    "print(f\"\\nTotal input findings: {total_findings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter_output = await interpret(extractor_outputs, baseline_sheets)\n",
    "\n",
    "print(f\"Reconciled findings: {len(interpreter_output.reconciled_findings)}\")\n",
    "print(f\"Conflicts resolved:  {len(interpreter_output.conflicts_resolved)}\")\n",
    "print(f\"Duplicates removed:  {interpreter_output.duplicates_removed}\")\n",
    "print(f\"Input findings:      {interpreter_output.metadata.total_input_findings}\")\n",
    "print(f\"Output findings:     {interpreter_output.metadata.total_output_findings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconciled Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i, rf in enumerate(interpreter_output.reconciled_findings, 1):\n",
    "    sources = \", \".join(rf.sources)\n",
    "    note = rf.resolution_note or \"—\"\n",
    "    content_preview = rf.content[:100] + (\"…\" if len(rf.content) > 100 else \"\")\n",
    "    rows.append(f\"| {i} | {rf.datetime or '—'} | {content_preview} | {sources} | {note} |\")\n",
    "\n",
    "table = (\n",
    "    \"| # | Datetime | Content | Sources | Resolution Note |\\n\"\n",
    "    \"|---|----------|---------|---------|-----------------|\\n\"\n",
    "    + \"\\n\".join(rows)\n",
    ")\n",
    "display(Markdown(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conflict Resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not interpreter_output.conflicts_resolved:\n",
    "    display(Markdown(\"*No conflicts detected.*\"))\n",
    "else:\n",
    "    for i, cr in enumerate(interpreter_output.conflicts_resolved, 1):\n",
    "        md = (\n",
    "            f\"### Conflict {i}\\n\\n\"\n",
    "            f\"**Description:** {cr.description}\\n\\n\"\n",
    "            f\"**Sources:** {', '.join(cr.sources)}\\n\\n\"\n",
    "            f\"**Resolution:** {cr.resolution}\"\n",
    "        )\n",
    "        display(Markdown(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "interp_path = OUTPUT_DIR / \"interpretation.json\"\n",
    "interp_path.write_text(\n",
    "    json.dumps(interpreter_output.model_dump(), ensure_ascii=False, indent=2),\n",
    "    encoding=\"utf-8\",\n",
    ")\n",
    "print(f\"Saved: {interp_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}